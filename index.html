<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<style type="text/css">
body.ex1 {
  font-size:14pt;  
  text-align:justify;
  background-color:white;
}
hr {
  border: 0;
  width: 80%;
}
img.w3c {
  float:left;
  border:none;
}
img {
  float:right;
  border:none;
}
p.footer {
  font-size:9pt
}
hr.footer {
  border: none;
  border-top: dashed 1px #00CC33;
  color: #ffffff;
  background-color: #ffffff;
}
div.inner {
  width:800px;
  padding-top:0px;
  margin-left: auto;
  margin-right: auto;
  background-color:white;
}
a {
  text-decoration:none; color:#005A9C; 
}
span.name {
  color:black;
}
div.hr { 
  width: 100%; 
  height: 1px; 
  border: 0; 
  background-color: gray; 
  margin-top: 5px; 
} 
li.pub {
  margin-bottom: 10px
}
</style>

<title>Wenduan Xu</title>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-31571478-1']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>

<body class="ex1">
<br/><br/>
<div class="inner">
<header>
<h2>About</h2>
</header>
I am interested in naural language understanding, especially neural network models and learning algorithms which are able to discover, capture, represent, generalize, and transfer (meta)understanding for and across tasks of human cognition involving languages.
 <br/><br/>
My thesis focused on structured prediction methods for models including recurrent neural networks, with the unifying theme of integrating structured learning with inexact search. As one contribution, I developed a reinforcement learning-style learning algorithm &#8211 with applicability beyond parsing &#8211 along with the first neural network parsing model optimized for the final evaluation metric with a structure-level loss.
<br/><br/>
I approach parsing as a typical and interesting structured prediction task. I tend to believe it is likely to be of limited use in end-to-end language processing approaches, and in the endeavor to achieve automated human-level language understanding, which remains elusive with currently available language technologies (more on this on the last page <a href="/papers/conclusion.pdf">here</a>). 
<br/><br/>
As the shift from natural language text processing to natural language understanding swiftly taking place, quite a few controversial issues have also been raised. Is structured prediction still important for neural network models? Is structure/linguistics necessary or a necessary evil? Are insights from neuroscience more relevant? Is language just a side effect of general intelligence? 
<br/><br/>
These are all unsettled issues, but I want to test unconventional ideas. 
<br/><br/>
Here is my <a href='/papers/research.pdf'>research statement</a>. 
<br/><br/>
</div>

<div class="inner">
<header>
<h2>Papers</h2>
</header>
<b>Structured Learning with Inexact Search: Advances in Shift-Reduce CCG Parsing</b><br/>Thesis<a href ='./papers/thesis.pdf'> pdf</a>  <a href = './talks/thesis-slides.pdf'>slides</a><br/><br/>
<b>LSTM Shift-Reduce CCG Parsing</b><br/>Wenduan Xu<br/>In EMNLP 2016 <a href = 'https://www.aclweb.org/anthology/D/D16/D16-1181v2.pdf'>pdf</a> <a href ='https://bitbucket.org/xwd/ccsr2015'>code</a> <br/><br/>
<b>Expected F-measure Training for Shift-Reduce Parsing with Recurrent Neural Networks</b><br/>Wenduan Xu, Michael Auli, and Stephen Clark<br/>In NAACL 2016 <a href = 'http://www.aclweb.org/anthology/N/N16/N16-1025.pdf' >pdf</a> <a href = './talks/naacl16.pdf'>slides</a> <a href ='https://bitbucket.org/xwd/ccsr2015'>code</a><br/><br/>
<b>Donâ€™t Interrupt Me While I Type: Inferring Text Entered Through Gesture Typing on Android Keyboards</b><br/>Laurent Simon, Wenduan Xu, and Ross Anderson<br/>In <a href='https://petsymposium.org/2016/spw-mirror/pets-2016/index.html'>PETS</a> 2016 <a href = './papers/sxa16.pdf'>pdf</a> <a href = 'https://www.lightbluetouchpaper.org/2016/07/29/yet-another-android-side-channel/'>blog</a><i><br/>Andreas Pfitzmann Best Student Paper runner-up</i><br/><br/>
<b>CCG Supertagging with a Recurrent Neural Network</b><br/>Wenduan Xu, Michael Auli, and Stephen Clark<br/>In ACL 2015 (short paper) <a href = 'http://www.aclweb.org/anthology/P15-2041'>pdf</a> <a href = './talks/acl15.pdf'>slides</a> <a href ='https://bitbucket.org/xwd/candc-rnn'>code</a> <br/><br/>
<b>Shift-Reduce CCG Parsing with a Dependency Model</b><br/>Wenduan Xu, Stephen Clark, and Yue Zhang<br/>In ACL 2014 <a href = 'http://aclweb.org/anthology/P/P14/P14-1021.pdf'>pdf</a> <a href = 'errata'>errata</a> <a href = './talks/acl14.pdf'>slides</a> <a href ='https://bitbucket.org/xwd/ccsr2014'>code</a><br/><br/>
<b>Learning to Prune: Context-Sensitive Pruning for Syntactic MT</b><br/>Wenduan Xu, Yue Zhang, Philip Williams, and Philipp Koehn<br/> In ACL 2013 (short paper) <a href = './papers/acl13.pdf'>pdf</a> <a href='poster.pdf'>poster</a> <a href="csp">code</a> <br/><br/>
<b>Extending Hiero Decoding in Moses with Cube Growing</b><br/>Wenduan Xu and Philipp Koehn<br/>PBML <a href="./papers/art-xu-koehn.pdf">pdf</a><br/>(Presented at the 7th MT Marathon 2012.)
</div>
</body>
<br/><br/><br/><br/><br/>
</html>

